{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Relevant Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('credit_card_default_train.csv')\n",
    "test_data = pd.read_csv('credit_card_default_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Gender','EDUCATION_STATUS','MARITAL_STATUS','AGE','PAY_JULY','PAY_AUG','PAY_SEP','PAY_OCT','PAY_NOV','PAY_DEC']\n",
    "target = 'NEXT_MONTH_DEFAULT'\n",
    "ID = 'Client_ID'\n",
    "num_cols = [col for col in train_data.columns.tolist() if col not in cat_cols +[target]+[ID]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Paid_Due_July(row):\n",
    "    if row['PAID_AMT_JULY'] == 0:\n",
    "        val = row['DUE_AMT_JULY']\n",
    "    else:\n",
    "        val = row['DUE_AMT_JULY']/row['PAID_AMT_JULY']\n",
    "    return val\n",
    "\n",
    "def Paid_Due_Aug(row):\n",
    "    if row['PAID_AMT_AUG'] == 0:\n",
    "        val = row['DUE_AMT_AUG']\n",
    "    else:\n",
    "        val = row['DUE_AMT_AUG']/row['PAID_AMT_AUG']\n",
    "    return val\n",
    "\n",
    "def Paid_Due_Sep(row):\n",
    "    if row['PAID_AMT_SEP'] == 0:\n",
    "        val = row['DUE_AMT_SEP']\n",
    "    else:\n",
    "        val = row['DUE_AMT_SEP']/row['PAID_AMT_SEP']\n",
    "    return val\n",
    "\n",
    "def Paid_Due_Oct(row):\n",
    "    if row['PAID_AMT_OCT'] == 0:\n",
    "        val = row['DUE_AMT_OCT']\n",
    "    else:\n",
    "        val = row['DUE_AMT_OCT']/row['PAID_AMT_OCT']\n",
    "    return val\n",
    "\n",
    "def Paid_Due_Nov(row):\n",
    "    if row['PAID_AMT_NOV'] == 0:\n",
    "        val = row['DUE_AMT_NOV']\n",
    "    else:\n",
    "        val = row['DUE_AMT_NOV']/row['PAID_AMT_NOV']\n",
    "    return val\n",
    "\n",
    "def Paid_Due_Dec(row):\n",
    "    if row['PAID_AMT_DEC'] == 0:\n",
    "        val = row['DUE_AMT_DEC']\n",
    "    else:\n",
    "        val = row['DUE_AMT_DEC']/row['PAID_AMT_DEC']\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['PAID_DUE_JULY'] = train_data.apply(Paid_Due_July, axis=1)\n",
    "train_data['PAID_DUE_AUG'] = train_data.apply(Paid_Due_Aug, axis=1)\n",
    "train_data['PAID_DUE_SEP'] = train_data.apply(Paid_Due_Sep, axis=1)\n",
    "train_data['PAID_DUE_OCT'] = train_data.apply(Paid_Due_Oct, axis=1)\n",
    "train_data['PAID_DUE_NOV'] = train_data.apply(Paid_Due_Nov, axis=1)\n",
    "train_data['PAID_DUE_DEC'] = train_data.apply(Paid_Due_Dec, axis=1)\n",
    "\n",
    "test_data['PAID_DUE_JULY'] = test_data.apply(Paid_Due_July, axis=1)\n",
    "test_data['PAID_DUE_AUG'] = test_data.apply(Paid_Due_Aug, axis=1)\n",
    "test_data['PAID_DUE_SEP'] = test_data.apply(Paid_Due_Sep, axis=1)\n",
    "test_data['PAID_DUE_OCT'] = test_data.apply(Paid_Due_Oct, axis=1)\n",
    "test_data['PAID_DUE_NOV'] = test_data.apply(Paid_Due_Nov, axis=1)\n",
    "test_data['PAID_DUE_DEC'] = test_data.apply(Paid_Due_Dec, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['PAY_TOT'] = train_data['PAY_JULY'] + train_data['PAY_AUG'] + train_data['PAY_SEP'] + train_data['PAY_OCT'] + train_data['PAY_NOV'] + train_data['PAY_DEC']\n",
    "test_data['PAY_TOT'] = test_data['PAY_JULY'] + test_data['PAY_AUG'] + test_data['PAY_SEP'] + test_data['PAY_OCT'] + test_data['PAY_NOV'] + test_data['PAY_DEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isZero(row):\n",
    "    if row['PAY_TOT'] == 0:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['PAY_TOT_0'] = train_data.apply(isZero, axis=1)\n",
    "test_data['PAY_TOT_0'] = test_data.apply(isZero, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelEncoder = LabelEncoder()\n",
    "train_data['Balance_Limit_V1_cat'] = LabelEncoder.fit_transform(train_data['Balance_Limit_V1'])\n",
    "train_data['Gender_cat'] = LabelEncoder.fit_transform(train_data['Gender'])\n",
    "train_data['EDUCATION_STATUS_cat'] = LabelEncoder.fit_transform(train_data['EDUCATION_STATUS'])\n",
    "train_data['MARITAL_STATUS_cat'] = LabelEncoder.fit_transform(train_data['MARITAL_STATUS'])\n",
    "train_data['AGE_cat'] = LabelEncoder.fit_transform(train_data['AGE'])\n",
    "\n",
    "test_data['Balance_Limit_V1_cat'] = LabelEncoder.fit_transform(test_data['Balance_Limit_V1'])\n",
    "test_data['Gender_cat'] = LabelEncoder.fit_transform(test_data['Gender'])\n",
    "test_data['EDUCATION_STATUS_cat'] = LabelEncoder.fit_transform(test_data['EDUCATION_STATUS'])\n",
    "test_data['MARITAL_STATUS_cat'] = LabelEncoder.fit_transform(test_data['MARITAL_STATUS'])\n",
    "test_data['AGE_cat'] = LabelEncoder.fit_transform(test_data['AGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data.drop([target,ID,'Balance_Limit_V1','Gender','EDUCATION_STATUS','MARITAL_STATUS','AGE'],axis=1), \n",
    "                                                    train_data[target], test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] learning_rate=0.1, n_estimators=100 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . learning_rate=0.1, n_estimators=100, score=0.808, total=   4.0s\n",
      "[CV] learning_rate=0.1, n_estimators=100 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . learning_rate=0.1, n_estimators=100, score=0.823, total=   4.0s\n",
      "[CV] learning_rate=0.1, n_estimators=100 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . learning_rate=0.1, n_estimators=100, score=0.824, total=   3.9s\n",
      "[CV] learning_rate=0.1, n_estimators=200 .............................\n",
      "[CV] . learning_rate=0.1, n_estimators=200, score=0.808, total=   7.8s\n",
      "[CV] learning_rate=0.1, n_estimators=200 .............................\n",
      "[CV] . learning_rate=0.1, n_estimators=200, score=0.823, total=   8.0s\n",
      "[CV] learning_rate=0.1, n_estimators=200 .............................\n",
      "[CV] . learning_rate=0.1, n_estimators=200, score=0.824, total=   8.0s\n",
      "[CV] learning_rate=0.1, n_estimators=400 .............................\n",
      "[CV] . learning_rate=0.1, n_estimators=400, score=0.809, total=  15.7s\n",
      "[CV] learning_rate=0.1, n_estimators=400 .............................\n",
      "[CV] . learning_rate=0.1, n_estimators=400, score=0.822, total=  15.7s\n",
      "[CV] learning_rate=0.1, n_estimators=400 .............................\n",
      "[CV] . learning_rate=0.1, n_estimators=400, score=0.825, total=  15.6s\n",
      "[CV] learning_rate=0.01, n_estimators=100 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=100, score=0.810, total=   3.9s\n",
      "[CV] learning_rate=0.01, n_estimators=100 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=100, score=0.824, total=   4.0s\n",
      "[CV] learning_rate=0.01, n_estimators=100 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=100, score=0.820, total=   3.9s\n",
      "[CV] learning_rate=0.01, n_estimators=200 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=200, score=0.810, total=   7.8s\n",
      "[CV] learning_rate=0.01, n_estimators=200 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=200, score=0.824, total=   7.9s\n",
      "[CV] learning_rate=0.01, n_estimators=200 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=200, score=0.820, total=   8.0s\n",
      "[CV] learning_rate=0.01, n_estimators=400 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=400, score=0.810, total=  16.1s\n",
      "[CV] learning_rate=0.01, n_estimators=400 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=400, score=0.823, total=  16.2s\n",
      "[CV] learning_rate=0.01, n_estimators=400 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=400, score=0.820, total=  16.0s\n",
      "[CV] learning_rate=0.03, n_estimators=100 ............................\n",
      "[CV]  learning_rate=0.03, n_estimators=100, score=0.810, total=   4.0s\n",
      "[CV] learning_rate=0.03, n_estimators=100 ............................\n",
      "[CV]  learning_rate=0.03, n_estimators=100, score=0.823, total=   4.6s\n",
      "[CV] learning_rate=0.03, n_estimators=100 ............................\n",
      "[CV]  learning_rate=0.03, n_estimators=100, score=0.819, total=   4.1s\n",
      "[CV] learning_rate=0.03, n_estimators=200 ............................\n",
      "[CV]  learning_rate=0.03, n_estimators=200, score=0.808, total=   7.8s\n",
      "[CV] learning_rate=0.03, n_estimators=200 ............................\n",
      "[CV]  learning_rate=0.03, n_estimators=200, score=0.822, total=   7.8s\n",
      "[CV] learning_rate=0.03, n_estimators=200 ............................\n",
      "[CV]  learning_rate=0.03, n_estimators=200, score=0.822, total=   8.1s\n",
      "[CV] learning_rate=0.03, n_estimators=400 ............................\n",
      "[CV]  learning_rate=0.03, n_estimators=400, score=0.809, total=  15.9s\n",
      "[CV] learning_rate=0.03, n_estimators=400 ............................\n",
      "[CV]  learning_rate=0.03, n_estimators=400, score=0.822, total=  15.7s\n",
      "[CV] learning_rate=0.03, n_estimators=400 ............................\n",
      "[CV]  learning_rate=0.03, n_estimators=400, score=0.824, total=  15.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=None,\n",
       "                                          learning_rate=1.0, n_estimators=50,\n",
       "                                          random_state=None),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.1, 0.01, 0.03],\n",
       "                         'n_estimators': [100, 200, 400]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data.drop([target,ID,'Balance_Limit_V1','Gender','EDUCATION_STATUS','MARITAL_STATUS','AGE'],axis=1)\n",
    "y = train_data[target]\n",
    "                    \n",
    "random_grid = {'n_estimators': [100,200,400],\n",
    "               'learning_rate': [0.1,0.01,0.03]}\n",
    "\n",
    "grid = GridSearchCV(AdaBoostClassifier(),random_grid,refit=True,verbose=3,cv=3)\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'n_estimators': 400}\n",
      "0.8186666666666667\n"
     ]
    }
   ],
   "source": [
    "print (grid.best_params_)\n",
    "print (grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.1,\n",
       "                   n_estimators=400, random_state=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ada = AdaBoostClassifier(n_estimators=400,learning_rate = 0.1)\n",
    "model_ada.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      5553\n",
      "           1       0.68      0.33      0.45      1647\n",
      "\n",
      "    accuracy                           0.81      7200\n",
      "   macro avg       0.76      0.64      0.67      7200\n",
      "weighted avg       0.79      0.81      0.79      7200\n",
      "\n",
      "\n",
      "\n",
      "[[5299  254]\n",
      " [1101  546]]\n"
     ]
    }
   ],
   "source": [
    "preds_ada = model_ada.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,preds_ada))\n",
    "print ('\\n')\n",
    "print(confusion_matrix(y_test,preds_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the model in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.01,\n",
       "                   n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ada = AdaBoostClassifier(n_estimators=200,learning_rate = 0.01)\n",
    "model_ada.fit(train_data.drop([target,ID,'Balance_Limit_V1','Gender','EDUCATION_STATUS','MARITAL_STATUS','AGE'],axis=1),train_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ada = model_ada.predict(test_data.drop([ID,'Balance_Limit_V1','Gender','EDUCATION_STATUS','MARITAL_STATUS','AGE'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.DataFrame(columns=[ID,target])\n",
    "sample_submission[ID]=test_data[ID]\n",
    "sample_submission[target] = preds_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_submission.to_csv('data-storm-day1-2 check.csv',index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypython",
   "language": "python",
   "name": "mypython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
