{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Importing the dataset\n",
    "from time import gmtime, strftime\n",
    "import gc\n",
    "from sklearn.model_selection import (train_test_split, GridSearchCV)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (roc_curve, auc, accuracy_score)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new features are generated \n",
    "\n",
    "train_data = pd.read_csv('E:/ML_IP/ML_projects/datastorm/credit_card_default_train.csv')\n",
    "predict_data = pd.read_csv('E:/ML_IP/ML_projects/datastorm/credit_card_default_test.csv')\n",
    "\n",
    "#new engineered features\n",
    "train_data['PAY_JULY_GREAT2']=train_data['PAY_JULY']>1.5 #APPLY ONE-HOT\n",
    "train_data['PAY_AUG_GREAT1']=train_data['PAY_AUG']>1 #APPLY ONE-HOT\n",
    "train_data['PAY_SEP_GREAT1']=train_data['PAY_SEP']>1 #APPLY ONE-HOT\n",
    "train_data['PAY_OCT_GREAT1']=train_data['PAY_OCT']>1 #APPLY ONE-HOT\n",
    "train_data['PAY_NOV_GREAT1']=train_data['PAY_NOV']>1 #APPLY ONE-HOT\n",
    "train_data['PAY_DEC_GREAT1']=train_data['PAY_DEC']>1 #APPLY ONE-HOT\n",
    "train_data['TOT']=train_data['PAY_JULY']+train_data['PAY_AUG']+train_data['PAY_SEP']+train_data['PAY_OCT']+train_data['PAY_NOV']+train_data['PAY_DEC']\n",
    "\n",
    "\n",
    "predict_data['PAY_JULY_GREAT2']=predict_data['PAY_JULY']>1.5 #APPLY ONE-HOT\n",
    "predict_data['PAY_AUG_GREAT1']=predict_data['PAY_AUG']>1 #APPLY ONE-HOT\n",
    "predict_data['PAY_SEP_GREAT1']=predict_data['PAY_SEP']>1 #APPLY ONE-HOT\n",
    "predict_data['PAY_OCT_GREAT1']=predict_data['PAY_OCT']>1 #APPLY ONE-HOT\n",
    "predict_data['PAY_NOV_GREAT1']=predict_data['PAY_NOV']>1 #APPLY ONE-HOT\n",
    "predict_data['PAY_DEC_GREAT1']=predict_data['PAY_DEC']>1 #APPLY ONE-HOT\n",
    "predict_data['TOT']=predict_data['PAY_JULY']+predict_data['PAY_AUG']+predict_data['PAY_SEP']+predict_data['PAY_OCT']+predict_data['PAY_NOV']+predict_data['PAY_DEC']\n",
    "\n",
    "\n",
    "cat_cols=['Gender', 'EDUCATION_STATUS',\n",
    "       'MARITAL_STATUS', 'AGE', 'PAY_JULY_GREAT2',\n",
    "       'PAY_AUG_GREAT1', 'PAY_SEP_GREAT1', 'PAY_OCT_GREAT1', 'PAY_NOV_GREAT1',\n",
    "       'PAY_DEC_GREAT1']\n",
    "train_data = pd.get_dummies( train_data,columns = cat_cols )\n",
    "predict_data = pd.get_dummies( predict_data,columns = cat_cols )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=train_data.drop(['Client_ID', 'Balance_Limit_V1', 'PAY_AUG', 'PAY_SEP',\n",
    "       'PAY_OCT', 'PAY_NOV', 'PAY_DEC', \n",
    "         'Gender_F',\n",
    "       'Gender_M', 'EDUCATION_STATUS_Graduate', 'EDUCATION_STATUS_High School',\n",
    "       'EDUCATION_STATUS_Other', 'MARITAL_STATUS_Other',\n",
    "       'MARITAL_STATUS_Single', 'AGE_31-45', 'AGE_46-65', 'AGE_Less than 30',\n",
    "       'AGE_More than 65', 'PAY_SEP_GREAT1_False',\n",
    "       'PAY_SEP_GREAT1_True', 'PAY_OCT_GREAT1_False', 'PAY_OCT_GREAT1_True',\n",
    "       'PAY_NOV_GREAT1_False', 'PAY_NOV_GREAT1_True', 'PAY_DEC_GREAT1_False',\n",
    "       'PAY_DEC_GREAT1_True'],axis=1)\n",
    "\n",
    "\n",
    "t2=predict_data.drop(['Client_ID', 'Balance_Limit_V1', 'PAY_AUG', 'PAY_SEP',\n",
    "       'PAY_OCT', 'PAY_NOV', 'PAY_DEC', \n",
    "         'Gender_F',\n",
    "       'Gender_M', 'EDUCATION_STATUS_Graduate', 'EDUCATION_STATUS_High School',\n",
    "       'EDUCATION_STATUS_Other', 'MARITAL_STATUS_Other',\n",
    "       'MARITAL_STATUS_Single', 'AGE_31-45', 'AGE_46-65', 'AGE_Less than 30',\n",
    "       'AGE_More than 65', 'PAY_SEP_GREAT1_False',\n",
    "       'PAY_SEP_GREAT1_True', 'PAY_OCT_GREAT1_False', 'PAY_OCT_GREAT1_True',\n",
    "       'PAY_NOV_GREAT1_False', 'PAY_NOV_GREAT1_True', 'PAY_DEC_GREAT1_False',\n",
    "       'PAY_DEC_GREAT1_True'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ud, X, y_train_ud, y = train_test_split(t1.drop('NEXT_MONTH_DEFAULT',axis=1),t1['NEXT_MONTH_DEFAULT'],test_size = 0.3,shuffle=True)\n",
    "X_val_ud, X_test_ud, y_val_ud, y_test_ud = train_test_split(X,y,test_size = 0.5,shuffle=False) \n",
    "\n",
    "X_predict_ud=t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20c09d107f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_ud.value_counts().plot(kind='bar', title='Count (target)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros=RandomOverSampler(random_state=0)\n",
    "#X_train_ud,y_train_ud=ros.fit_resample(X_train_ud,y_train_ud)\n",
    "#X_val_ud,y_val_ud=ros.fit_resample(X_val_ud,y_val_ud)\n",
    "#X_test_ud,y_test_ud=ros.fit_resample(X_test_ud,y_test_ud)\n",
    "\n",
    "std_scale = MinMaxScaler().fit(X_train_ud)\n",
    "X_train_ud = pd.DataFrame(std_scale.transform(X_train_ud))\n",
    "X_test_ud  = pd.DataFrame(std_scale.transform(X_test_ud))\n",
    "X_val_ud  = pd.DataFrame(std_scale.transform(X_val_ud))\n",
    "X_predict_ud  = pd.DataFrame(std_scale.transform(X_predict_ud))\n",
    "#X_predict  = pd.DataFrame(std_scale.transform(predict_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train=X_train_ud\n",
    "x_test=X_test_ud\n",
    "y_train=y_train_ud\n",
    "y_test=y_test_ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      2810\n",
      "           1       0.65      0.35      0.45       790\n",
      "\n",
      "    accuracy                           0.81      3600\n",
      "   macro avg       0.74      0.65      0.67      3600\n",
      "weighted avg       0.80      0.81      0.79      3600\n",
      "\n",
      "\n",
      "\n",
      "[[2660  150]\n",
      " [ 517  273]]\n",
      "prev\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      2810\n",
      "           1       0.62      0.37      0.46       790\n",
      "\n",
      "    accuracy                           0.81      3600\n",
      "   macro avg       0.73      0.65      0.68      3600\n",
      "weighted avg       0.79      0.81      0.79      3600\n",
      "\n",
      "\n",
      "\n",
      "[[2631  179]\n",
      " [ 497  293]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      2791\n",
      "           1       0.66      0.37      0.48       809\n",
      "\n",
      "    accuracy                           0.82      3600\n",
      "   macro avg       0.75      0.66      0.68      3600\n",
      "weighted avg       0.80      0.82      0.80      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_train = lgb.Dataset(x_train, label=y_train)\n",
    "params_best = {}\n",
    "params_best['learning_rate'] = 0.1\n",
    "params_best['boosting_type'] = 'dart'\n",
    "params_best['objective'] = 'binary'\n",
    "params_best['metric'] = 'binary_logloss'\n",
    "params_best['sub_feature'] = 0.7\n",
    "params_best['num_leaves'] = 18\n",
    "params_best['min_data'] = 70\n",
    "params_best['max_depth'] = 510\n",
    "params_best['max_bin']=120\n",
    "params_best['n_estimators']=110\n",
    "params_best['colsample_bytree' ]=0\n",
    "\n",
    "params_best = {}\n",
    "params = {}\n",
    "params['learning_rate'] = [0.1]\n",
    "params['boosting_type'] = ['dart']\n",
    "params['objective'] = ['binary']\n",
    "params['metric'] = ['binary_logloss']\n",
    "params['sub_feature'] = [0.7]\n",
    "params['num_leaves'] = [18]\n",
    "params['min_data'] = [70]\n",
    "params['max_depth'] = [510]\n",
    "params['max_bin']=[120]\n",
    "params['n_estimators']=[110]\n",
    "\n",
    "params2={}\n",
    "params2['learning_rate'] = 0.03\n",
    "params2['boosting_type'] = 'rf'\n",
    "params2['objective'] = 'binary'\n",
    "params2['metric'] = 'binary_logloss'\n",
    "params2['bagging_fraction'] = 0.5\n",
    "params2['feature_fraction'] = 0.8\n",
    "params2['bagging_freq'] = 1\n",
    "params2['num_leaves'] = 24\n",
    "params2['min_data'] = 50\n",
    "params2['max_depth'] = 10\n",
    "params2['max_bin']=20\n",
    "\n",
    "clf = lgb.train(params_best, d_train, 100)\n",
    "clf_a = lgb.train(params2, d_train, 100) #prev_max\n",
    "\n",
    "#Prediction\n",
    "test_probs = clf.predict(x_test)\n",
    "test_probs_a = clf_a.predict(x_test)\n",
    "\n",
    "\n",
    "def avoid_prob(preds_lgb):\n",
    "    for i in range(len(preds_lgb)):\n",
    "        if preds_lgb[i]>=0.5:       # setting threshold to .5\n",
    "            preds_lgb[i]=1\n",
    "        else:\n",
    "            preds_lgb[i]=0\n",
    "    return preds_lgb\n",
    "\n",
    "test_preds=avoid_prob(test_probs)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix,roc_auc_score,roc_curve\n",
    "\n",
    "print(classification_report(y_test,test_preds))\n",
    "print ('\\n')\n",
    "print(confusion_matrix(y_test,test_preds))\n",
    "#####\n",
    "print('prev')\n",
    "test_probs=test_probs_a\n",
    "test_preds=avoid_prob(test_probs)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix,roc_auc_score,roc_curve\n",
    "\n",
    "print(classification_report(y_test,test_preds))\n",
    "print ('\\n')\n",
    "print(confusion_matrix(y_test,test_preds))\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_val_ud,avoid_prob( clf.predict(X_val_ud))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type', 'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight', 'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample', 'subsample_for_bin', 'subsample_freq'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use gridsearchcv\n",
    "\n",
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', \n",
    "          objective = 'binary', \n",
    "          n_jobs = 5, \n",
    "          silent = True,\n",
    "          max_depth = 10)\n",
    "\n",
    "# To view the default model parameters:\n",
    "mdl.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    3.2s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'dart', 'learning_rate': 0.1, 'max_bin': 120, 'max_depth': 510, 'metric': 'binary_logloss', 'min_data': 70, 'n_estimators': 110, 'num_leaves': 18, 'objective': 'binary', 'sub_feature': 0.7}\n",
      "0.818154761904762\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005, 0.01],\n",
    "    'n_estimators': [8,16,24],\n",
    "    'num_leaves': [6,8,12,16], # large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "    'boosting_type' : ['gbdt', 'dart'], # for better accuracy -> try dart\n",
    "    'objective' : ['binary'],\n",
    "    'max_bin':[255, 510], # large max_bin helps improve accuracy but might slow down training progress\n",
    "    'random_state' : [500],\n",
    "    'colsample_bytree' : [0.64, 0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "'''\n",
    "params = {}\n",
    "params['learning_rate'] = [0.003,0.001,0.1]\n",
    "params['boosting_type'] = ['gbdt','dart','rf','goss']\n",
    "params['objective'] = ['binary']\n",
    "params['metric'] = ['binary_logloss']\n",
    "params['sub_feature'] = [0.5,0.2,0.8]\n",
    "params['num_leaves'] = [6,10,14,18,22]\n",
    "params['min_data'] = [30,50,70]\n",
    "params['max_depth'] = [7,10,15,20]\n",
    "'''\n",
    "\n",
    "params = {}\n",
    "params['learning_rate'] = [0.1]\n",
    "params['boosting_type'] = ['dart']\n",
    "params['objective'] = ['binary']\n",
    "params['metric'] = ['binary_logloss']\n",
    "params['sub_feature'] = [0.7]\n",
    "params['num_leaves'] = [18]\n",
    "params['min_data'] = [70]\n",
    "params['max_depth'] = [510]\n",
    "params['max_bin']=[120]\n",
    "params['n_estimators']=[110]\n",
    "\n",
    "\n",
    "grid = GridSearchCV(mdl, params, verbose=1, cv=4, n_jobs=-1)\n",
    "# Run the grid\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "probs=grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_best = {}\n",
    "params_best['learning_rate'] = 0.1\n",
    "params_best['boosting_type'] = 'dart'\n",
    "params_best['objective'] = 'binary'\n",
    "params_best['metric'] = 'binary_logloss'\n",
    "params_best['sub_feature'] = 0.5\n",
    "params_best['num_leaves'] = 18\n",
    "params_best['min_data'] = 70\n",
    "params_best['max_depth'] = 5\n",
    "params_best['max_bin']=250\n",
    "params_best['n_estimators']=110\n",
    "params_best['colsample_bytree' ]=0\n",
    "params_best['subsample']=0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'probs' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "probs=grid.predict(X_predict_ud) #this is used as the submission\n",
    "%store probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
